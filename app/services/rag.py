"""
RAGæœåŠ¡ - æ··åˆæ£€ç´¢ç‰ˆæœ¬
=====================
æ ¸å¿ƒæ”¹è¿›:
1. å‘é‡æ£€ç´¢ + BM25å…³é”®è¯æ£€ç´¢ (æ··åˆå¬å›)
2. RRFç®—æ³•èåˆç»“æœ
3. å¢åŠ debugæ¨¡å¼,å¯è§‚æµ‹æ£€ç´¢è¿‡ç¨‹
4. æ”¯æŒmetadata(doc_id/source)
"""

from app.utils.llm_client import LLMClient
from langchain_text_splitters import RecursiveCharacterTextSplitter
from app.services.minio import MINIOservice
from app.services.milvus import MILVUSService
from dotenv import load_dotenv
from pymilvus import Collection
from rank_bm25 import BM25Okapi
import jieba
import os

load_dotenv()


class RAG:
    # ==================== é…ç½®å‚æ•° ====================
    SIMILARITY_THRESHOLD = 3.0  # L2è·ç¦»é˜ˆå€¼(å·²æ”¾å®½,åŸ0.8å¤ªä¸¥æ ¼)
    MAX_CHUNK_LENGTH = 1900     # æœ€å¤§chunké•¿åº¦(ä¸Milvus schemaä¸€è‡´)
    
    # BM25ç´¢å¼•(ç±»å˜é‡,æ‰€æœ‰å®ä¾‹å…±äº«)
    _bm25_index = None
    _bm25_corpus = []  # å­˜å‚¨æ‰€æœ‰chunkåŸæ–‡
    
    # ==================== æ–‡æ¡£åŠ è½½ ====================
    @staticmethod
    def load_texts(file_path, object_name):
        """
        ä»MinIOä¸‹è½½æ–‡ä»¶å¹¶è¯»å–å†…å®¹
        
        Args:
            file_path: æœ¬åœ°ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            object_name: MinIOä¸­çš„å¯¹è±¡å
            
        Returns:
            str: æ–‡ä»¶æ–‡æœ¬å†…å®¹
        """
        minio = MINIOservice()
        result = minio.download_file(object_name, file_path)
        
        # æ£€æŸ¥ä¸‹è½½æ˜¯å¦æˆåŠŸ
        if result.startswith("é”™è¯¯") or result.startswith("S3é”™è¯¯") or result.startswith("æœªçŸ¥é”™è¯¯"):
            raise Exception(f"MinIOä¸‹è½½å¤±è´¥: {result}")
        
        # å¦‚æœdownload_fileè¿”å›çš„æ˜¯æ–‡ä»¶å†…å®¹(æ–‡æœ¬),ç›´æ¥è¿”å›
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        else:
            return result
    
    # ==================== æ–‡æœ¬åˆ‡å— ====================
    @staticmethod
    def chunk_texts(text, chunk_size=200, overlap=40):
        """
        ä¼˜åŒ–åçš„æ–‡æœ¬åˆ‡å—ç­–ç•¥
        
        æ”¹è¿›ç‚¹:
        - chunk_sizeé™è‡³200(åŸ500å¯¹ä¸­æ–‡å¤ªå¤§)
        - overlapå¢è‡³40(å¢åŠ ä¸Šä¸‹æ–‡è¿ç»­æ€§)
        - å¢åŠ ä¸­æ–‡æ ‡ç‚¹åˆ†éš”ç¬¦
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            chunk_size: å•ä¸ªchunkæœ€å¤§å­—ç¬¦æ•°
            overlap: chunké—´é‡å å­—ç¬¦æ•°
            
        Returns:
            list[str]: åˆ‡åˆ†åçš„chunkåˆ—è¡¨
        """
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=overlap,
            separators=[
                "\n---",    # è‡ªå®šä¹‰åˆ†éš”ç¬¦(å¦‚é¢è¯•é¢˜)
                "\n\n",     # æ®µè½
                "\n",       # è¡Œ
                "ã€‚",       # ä¸­æ–‡å¥å·
                "!",        # æ„Ÿå¹å·
                "?",        # é—®å·
                ";",        # åˆ†å·
                " ",        # ç©ºæ ¼(æœ€åå…œåº•)
            ])
        chunked_texts = text_splitter.split_text(text)
        return chunked_texts
    
    # ==================== å‘é‡åŒ– ====================
    @staticmethod
    def embed_chunks(chunks):
        """
        å°†æ–‡æœ¬chunkè½¬ä¸ºå‘é‡
        
        Args:
            chunks: æ–‡æœ¬chunkåˆ—è¡¨
            
        Returns:
            list: å‘é‡åˆ—è¡¨
        """
        from app.utils.embedding import EmbeddingUtils
        embedder = EmbeddingUtils()
        vectors = embedder.embed_documents(chunks)
        return vectors

    # ==================== ä¸Šä¼ å‘é‡åˆ°Milvus ====================
    def upload_vectors(self, vectors, chunks):
        """
        å°†å‘é‡å’Œæ–‡æœ¬ä¸Šä¼ åˆ°Milvus
        
        TODO: åç»­éœ€è¦åŠ metadata(doc_id/source/chunk_index)
        
        Args:
            vectors: å‘é‡åˆ—è¡¨
            chunks: å¯¹åº”çš„æ–‡æœ¬chunkåˆ—è¡¨
        """
        milvus = MILVUSService()
        milvus.connect()
        collection = milvus.create_collection("L2", dim=len(vectors[0]))
        labels = [0] * len(chunks)  # TODO: æ”¹ä¸ºçœŸå®doc_id
        descs = chunks
        milvus.insert_vector(collection, vectors, labels, descs)
    
    # ==================== æ„å»ºBM25ç´¢å¼• ====================
    @classmethod
    def build_bm25_index(cls, chunks):
        """
        æ„å»ºBM25å…³é”®è¯ç´¢å¼•
        
        BM25åŸç†: åŸºäºè¯é¢‘çš„ç»å…¸æ£€ç´¢ç®—æ³•
        - è€ƒè™‘è¯é¢‘(TF)
        - è€ƒè™‘é€†æ–‡æ¡£é¢‘ç‡(IDF)
        - è€ƒè™‘æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–
        
        Args:
            chunks: æ–‡æœ¬chunkåˆ—è¡¨
        """
        print(f"ğŸ”¨ å¼€å§‹æ„å»ºBM25ç´¢å¼•,å…± {len(chunks)} ä¸ªchunks...")
        
        # åˆ†è¯: ä½¿ç”¨jiebaå¯¹æ¯ä¸ªchunkè¿›è¡Œä¸­æ–‡åˆ†è¯
        tokenized_corpus = [list(jieba.cut(chunk)) for chunk in chunks]
        
        # æ„å»ºBM25ç´¢å¼•
        cls._bm25_index = BM25Okapi(tokenized_corpus)
        cls._bm25_corpus = chunks  # ä¿å­˜åŸæ–‡,ç”¨äºåç»­è¿”å›
        
        print(f"âœ… BM25ç´¢å¼•æ„å»ºå®Œæˆ!")
    
    # ==================== å®Œæ•´æ„å»ºç´¢å¼•æµç¨‹ ====================
    @staticmethod
    def build_index(file_path, object_name):
        """
        å®Œæ•´ç´¢å¼•æ„å»ºæµç¨‹
        
        æµç¨‹:
        1. ä»MinIOä¸‹è½½æ–‡ä»¶
        2. åˆ‡åˆ†æ–‡æœ¬
        3. æ„å»ºå‘é‡ç´¢å¼•(Milvus)
        4. æ„å»ºå…³é”®è¯ç´¢å¼•(BM25)
        
        Args:
            file_path: æœ¬åœ°ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            object_name: MinIOå¯¹è±¡å
            
        Returns:
            int: chunkæ•°é‡
        """
        print(f"\n{'='*50}")
        print(f"å¼€å§‹æ„å»ºç´¢å¼•: {object_name}")
        print(f"{'='*50}\n")
        
        # æ­¥éª¤1: åŠ è½½æ–‡æœ¬
        text = RAG.load_texts(file_path, object_name)
        print(f"ğŸ“„ æ–‡æ¡£åŠ è½½æˆåŠŸ,æ€»é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # æ­¥éª¤2: åˆ‡åˆ†æ–‡æœ¬
        chunks = RAG.chunk_texts(text)
        print(f"âœ‚ï¸  æ–‡æœ¬åˆ‡åˆ†å®Œæˆ,å…± {len(chunks)} ä¸ªchunks")
        
        # æ­¥éª¤3: æ„å»ºå‘é‡ç´¢å¼•
        print(f"ğŸ”¢ å¼€å§‹å‘é‡åŒ–...")
        vectors = RAG.embed_chunks(chunks)
        rag = RAG()
        rag.upload_vectors(vectors, chunks)
        print(f"âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ!")
        
        # æ­¥éª¤4: æ„å»ºBM25ç´¢å¼•
        RAG.build_bm25_index(chunks)
        
        print(f"\n{'='*50}")
        print(f"ç´¢å¼•æ„å»ºå®Œæˆ! æ€»chunks: {len(chunks)}")
        print(f"{'='*50}\n")
        
        return len(chunks)

    # ==================== æ··åˆæ£€ç´¢æ ¸å¿ƒ ====================
    @staticmethod
    def hybrid_search(query, top_k=3, alpha=0.5, debug=False):
        """
        æ··åˆæ£€ç´¢: å‘é‡æ£€ç´¢ + BM25å…³é”®è¯æ£€ç´¢
        
        ç­–ç•¥:
        1. åˆ†åˆ«ç”¨å‘é‡å’ŒBM25å¬å› top_k*2 ä¸ªç»“æœ
        2. ä½¿ç”¨RRF(å€’æ•°æ’åèåˆ)ç®—æ³•åˆå¹¶
        3. è¿”å›èåˆåçš„top_kç»“æœ
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: æœ€ç»ˆè¿”å›çš„ç»“æœæ•°
            alpha: å‘é‡æ£€ç´¢æƒé‡(0~1), 1-alphaä¸ºBM25æƒé‡
            debug: æ˜¯å¦è¿”å›è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            
        Returns:
            list: æ£€ç´¢åˆ°çš„æ–‡æœ¬chunkåˆ—è¡¨
            æˆ– dict: debug=Trueæ—¶è¿”å›è¯¦ç»†ä¿¡æ¯
        """
        print(f"\n{'='*50}")
        print(f"ğŸ” æ··åˆæ£€ç´¢å¼€å§‹")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*50}\n")
        
        # ============ è·¯å¾„1: å‘é‡æ£€ç´¢ ============
        print(f"ğŸ“Š è·¯å¾„1: å‘é‡æ£€ç´¢ (å¬å› top_{top_k*2})")
        vector_results = RAG.vector_search(query, top_k=top_k*2)
        print(f"   å¬å› {len(vector_results)} ä¸ªç»“æœ\n")
        
        # ============ è·¯å¾„2: BM25å…³é”®è¯æ£€ç´¢ ============
        print(f"ğŸ”¤ è·¯å¾„2: BM25å…³é”®è¯æ£€ç´¢ (å¬å› top_{top_k*2})")
        bm25_results = RAG.bm25_search(query, top_k=top_k*2)
        print(f"   å¬å› {len(bm25_results)} ä¸ªç»“æœ\n")
        
        # ============ èåˆç­–ç•¥: RRF ============
        print(f"ğŸ”€ å¼€å§‹èåˆ (RRFç®—æ³•)...")
        merged_results = RAG.rrf_fusion(vector_results, bm25_results, top_k)
        print(f"   èåˆåä¿ç•™ {len(merged_results)} ä¸ªç»“æœ\n")
        
        print(f"{'='*50}")
        print(f"âœ… æ··åˆæ£€ç´¢å®Œæˆ")
        print(f"{'='*50}\n")
        
        if debug:
            return {
                "final_results": merged_results,
                "vector_results": vector_results[:5],
                "bm25_results": bm25_results[:5],
                "fusion_method": "RRF"
            }
        
        return merged_results
    
    # ==================== å‘é‡æ£€ç´¢ ====================
    @staticmethod
    def vector_search(query, top_k=5):
        """
        çº¯å‘é‡æ£€ç´¢ (ä½ åŸæ¥çš„searchæ–¹æ³•)
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: å¬å›æ•°é‡
            
        Returns:
            list[str]: æ£€ç´¢åˆ°çš„chunkæ–‡æœ¬åˆ—è¡¨
        """
        from app.utils.embedding import EmbeddingUtils
        milvus = MILVUSService()
        milvus.connect()
        collection_name = milvus.get_collection_name("L2")
        collection = Collection(collection_name)
        collection.load()

        # æŸ¥è¯¢å‘é‡åŒ–
        embedder = EmbeddingUtils()
        query_vector = embedder.embed_query(query)

        # Milvusæ£€ç´¢
        results = collection.search(
            data=[query_vector],
            anns_field="vector",
            param={"metric_type": "L2", "params": {"nprobe": 10}},
            limit=top_k*2,  # å¤šå¬å›ä¸€äº›,ç”¨äºè¿‡æ»¤
            output_fields=["desc"]
        )
        
        # ç›¸ä¼¼åº¦è¿‡æ»¤
        filtered_results = []
        for i, hit in enumerate(results[0]):
            distance = hit.distance
            content = hit.entity.get('desc')
            
            # åªä¿ç•™ç›¸ä¼¼åº¦é«˜çš„ç»“æœ
            if distance <= RAG.SIMILARITY_THRESHOLD:
                filtered_results.append(content)
        
        # å¦‚æœè¿‡æ»¤åä¸è¶³top_k,è¡¥å……ä¸€äº›æ¬¡ä¼˜ç»“æœ
        if len(filtered_results) < top_k and len(results[0]) > len(filtered_results):
            all_results = [hit.entity.get('desc') for hit in results[0]]
            remaining = top_k - len(filtered_results)
            additional = all_results[len(filtered_results):len(filtered_results)+remaining]
            filtered_results.extend(additional)
        
        return filtered_results[:top_k]
    
    # ==================== BM25æ£€ç´¢ ====================
    @classmethod
    def bm25_search(cls, query, top_k=5):
        """
        BM25å…³é”®è¯æ£€ç´¢
        
        é€‚ç”¨åœºæ™¯:
        - ä¸“æœ‰åè¯ (å¦‚"FastAPI")
        - ç²¾ç¡®åŒ¹é… (å¦‚ä»£ç ã€é…ç½®)
        - å‘é‡æ£€ç´¢å®¹æ˜“missçš„æƒ…å†µ
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: å¬å›æ•°é‡
            
        Returns:
            list[str]: æ£€ç´¢åˆ°çš„chunkæ–‡æœ¬åˆ—è¡¨
        """
        if cls._bm25_index is None:
            print("âš ï¸  BM25ç´¢å¼•æœªæ„å»º,è¿”å›ç©ºç»“æœ")
            return []
        
        # æŸ¥è¯¢åˆ†è¯
        tokenized_query = list(jieba.cut(query))
        
        # è®¡ç®—BM25åˆ†æ•°
        scores = cls._bm25_index.get_scores(tokenized_query)
        
        # å–top_k
        top_indices = scores.argsort()[-top_k:][::-1]  # é™åºæ’åˆ—
        results = [cls._bm25_corpus[i] for i in top_indices]
        
        return results
    
    # ==================== RRFèåˆç®—æ³• ====================
    @staticmethod
    def rrf_fusion(list1, list2, top_k, k=60):
        """
        RRF (Reciprocal Rank Fusion) å€’æ•°æ’åèåˆ
        
        åŸç†:
        - ä¸ä¾èµ–å…·ä½“åˆ†æ•°,åªçœ‹æ’å
        - score = 1/(k + rank)
        - å…¬å¹³å¯¹å¾…ä¸åŒæ£€ç´¢æº
        
        ç¤ºä¾‹:
        å‘é‡æ£€ç´¢: [A(rank=1), B(rank=2), C(rank=3)]
        BM25æ£€ç´¢: [B(rank=1), D(rank=2), A(rank=3)]
        
        Açš„æœ€ç»ˆåˆ†æ•°: 1/(60+1) + 1/(60+3) = 0.0164 + 0.0159 = 0.0323
        Bçš„æœ€ç»ˆåˆ†æ•°: 1/(60+2) + 1/(60+1) = 0.0161 + 0.0164 = 0.0325
        â†’ Bæ’ç¬¬ä¸€
        
        Args:
            list1: å‘é‡æ£€ç´¢ç»“æœåˆ—è¡¨
            list2: BM25æ£€ç´¢ç»“æœåˆ—è¡¨
            top_k: æœ€ç»ˆè¿”å›æ•°é‡
            k: RRFå¹³æ»‘å‚æ•°(é»˜è®¤60)
            
        Returns:
            list: èåˆåçš„top_kç»“æœ
        """
        scores = {}
        
        # è®¡ç®—list1çš„RRFåˆ†æ•°
        for rank, doc in enumerate(list1):
            scores[doc] = scores.get(doc, 0) + 1.0 / (k + rank + 1)
        
        # è®¡ç®—list2çš„RRFåˆ†æ•°
        for rank, doc in enumerate(list2):
            scores[doc] = scores.get(doc, 0) + 1.0 / (k + rank + 1)
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        return [doc for doc, score in sorted_docs[:top_k]]
    
    # ==================== å¯¹å¤–æ¥å£ (å…¼å®¹åŸæœ‰ä»£ç ) ====================
    @staticmethod
    def search(query, top_k=3, use_hybrid=True):
        """
        ç»Ÿä¸€æ£€ç´¢æ¥å£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°
            use_hybrid: æ˜¯å¦ä½¿ç”¨æ··åˆæ£€ç´¢(é»˜è®¤True)
            
        Returns:
            list[str]: æ£€ç´¢åˆ°çš„æ–‡æœ¬åˆ—è¡¨
        """
        if use_hybrid and RAG._bm25_index is not None:
            return RAG.hybrid_search(query, top_k)
        else:
            # é™çº§åˆ°çº¯å‘é‡æ£€ç´¢
            return RAG.vector_search(query, top_k)
    
    # ==================== é—®ç­”æ¥å£ ====================
    @staticmethod
    def ask(query, top_k=3, debug=False):
        """
        RAGé—®ç­”æ¥å£
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            top_k: å¬å›chunkæ•°é‡
            debug: æ˜¯å¦è¿”å›æ£€ç´¢è¯¦æƒ…
            
        Returns:
            str: LLMç”Ÿæˆçš„ç­”æ¡ˆ
            æˆ– dict: debug=Trueæ—¶è¿”å›è¯¦ç»†ä¿¡æ¯
        """
        # æ£€ç´¢ç›¸å…³æ–‡æœ¬
        if debug:
            search_result = RAG.hybrid_search(query, top_k=top_k, debug=True)
            texts = search_result["final_results"]
        else:
            texts = RAG.search(query, top_k=top_k)
        
        # ç”Ÿæˆç­”æ¡ˆ
        answer = RAG.generate_answer(texts, query)
        
        if debug:
            return {
                "question": query,
                "answer": answer,
                "contexts": [{"text": t[:100] + "...", "length": len(t)} 
                            for t in texts],
                "retrieval_details": search_result
            }
        
        return answer
    
    # ==================== ç­”æ¡ˆç”Ÿæˆ ====================
    @staticmethod
    def generate_answer(relevant_texts, query):
        """
        åŸºäºæ£€ç´¢åˆ°çš„æ–‡æœ¬ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            relevant_texts: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æœ¬åˆ—è¡¨
            query: ç”¨æˆ·é—®é¢˜
            
        Returns:
            str: LLMç”Ÿæˆçš„ç­”æ¡ˆ
        """
        llm = LLMClient.get_llm()
        
        if not relevant_texts or all(not t.strip() for t in relevant_texts):
            return "æŠ±æ­‰,æˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        
        # æ‹¼æ¥ä¸Šä¸‹æ–‡
        context = "\n\n---\n\n".join(relevant_texts)
        
        # æ„é€ prompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚

ã€é‡è¦è§„åˆ™ã€‘
1. ä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä½œä¸ºå‚è€ƒ,ç»“åˆä½ çš„çŸ¥è¯†åº“è¿›è¡Œå›ç­”ã€‚
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯,æ˜ç¡®è¯´"ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯"
3. å›ç­”æ—¶è¯·ç¡®ä¿ä¿¡æ¯å‡†ç¡®,ä¸è¦ç¼–é€ äº‹å®ã€‚
4. ä¿æŒå›ç­”ç®€æ´å‡†ç¡®

ã€ä¸Šä¸‹æ–‡ã€‘
{context}

ã€é—®é¢˜ã€‘
{query}

ã€å›ç­”ã€‘"""
        
        response = llm.invoke([{"role":"user","content":prompt}])
        return response.content